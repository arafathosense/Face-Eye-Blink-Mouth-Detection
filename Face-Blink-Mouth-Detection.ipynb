{
 "cells": [
  {
   "cell_type": "code",
   "id": "18c5812f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T11:28:04.857839Z",
     "start_time": "2025-11-30T11:28:04.845054Z"
    }
   },
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "3442bf68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T11:29:15.242003Z",
     "start_time": "2025-11-30T11:28:04.894813Z"
    }
   },
   "source": [
    "\n",
    "# CONFIGURATION \n",
    "EAR_THRESHOLD = 0.25 \n",
    "MAR_THRESHOLD = 0.10 \n",
    "\n",
    "# Eye indices for 6-point EAR\n",
    "Right_Eye = [33, 160, 158, 133, 153, 144]\n",
    "Left_Eye = [362, 385, 387, 263, 373, 380]\n",
    "# Lips indices (upper and lower points for vertical distance)\n",
    "Lip_Points = [13, 14]\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "def ear(pts):\n",
    "    \"\"\"Calculates the Eye Aspect Ratio (EAR) for a 6-point eye landmark set.\"\"\"\n",
    "    # Vertical distances\n",
    "    A = dist.euclidean(pts[1], pts[5])\n",
    "    B = dist.euclidean(pts[2], pts[4])\n",
    "    # Horizontal distance\n",
    "    C = dist.euclidean(pts[0], pts[3])\n",
    "    # EAR formula\n",
    "    return (A + B) / (2.0 * C) if C != 0 else 0.0\n",
    "\n",
    "def normalized_lip_distance(u, l):\n",
    "    \"\"\"Calculates the Euclidean distance between two face landmarks in normalized coordinates (0.0 to 1.0).\"\"\"\n",
    "    u_norm = np.array([u.x, u.y])\n",
    "    l_norm = np.array([l.x, l.y])\n",
    "    return np.linalg.norm(u_norm - l_norm)\n",
    "\n",
    "def pixel_landmarks(face, w, h):\n",
    "    \"\"\"Converts normalized landmarks to pixel coordinates.\"\"\"\n",
    "    return [(int(lm.x * w), int(lm.y * h)) for lm in face.landmark]\n",
    "\n",
    "def face_box(face, w, h):\n",
    "    \"\"\"Calculates the bounding box (min/max x/y) for a face.\"\"\"\n",
    "    xs = [lm.x for lm in face.landmark]\n",
    "    ys = [lm.y for lm in face.landmark]\n",
    "    x1, y1 = int(min(xs) * w), int(min(ys) * h)\n",
    "    x2, y2 = int(max(xs) * w), int(max(ys) * h)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "# --- MAIN FUNCTION ---\n",
    "def start_detection():\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    \n",
    "    # Track counters per-face\n",
    "    # L: Left Blink Count, R: Right Blink Count, M: Mouth Open Count\n",
    "    # prev_L/R: Previous state (1=Open, 0=Closed), prev_M: Previous state (1=Open, 0=Closed)\n",
    "    counters = {} \n",
    "\n",
    "    cv2.namedWindow(\"Face Blink Mouth Detection\", cv2.WINDOW_FREERATIO)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Variables for FPS calculation\n",
    "    p_time = 0\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, \n",
    "                               max_num_faces=10, refine_landmarks=True,\n",
    "                               min_detection_confidence=0.7,\n",
    "                               min_tracking_confidence=0.7) as mesh:\n",
    "\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok: continue\n",
    "            \n",
    "            frame = cv2.flip(frame, 1) # Mirror image for easier user interaction\n",
    "            h, w, _ = frame.shape\n",
    "\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = mesh.process(rgb)\n",
    "\n",
    "            # PROCESS FACES \n",
    "            if results.multi_face_landmarks:\n",
    "                for face_id, face in enumerate(results.multi_face_landmarks):\n",
    "\n",
    "                    # Ensure counter dictionary exists for each face\n",
    "                    if face_id not in counters:\n",
    "                        counters[face_id] = {\"L\":0, \"R\":0, \"M\":0,\n",
    "                                             \"prev_L\":1, \"prev_R\":1, \"prev_M\":0}\n",
    "\n",
    "                    pts = pixel_landmarks(face, w, h)\n",
    "\n",
    "                    # EYE EAR CALCULATION \n",
    "                    RE = [pts[i] for i in Right_Eye]\n",
    "                    LE = [pts[i] for i in Left_Eye]\n",
    "                    \n",
    "                    rEAR = ear(RE)\n",
    "                    lEAR = ear(LE)\n",
    "\n",
    "                    # --- BLINK DETECTION (Falling Edge Logic) ---\n",
    "                    # 100% accuracy to calculate the count in left eye open and close\n",
    "                    if lEAR < EAR_THRESHOLD and counters[face_id][\"prev_L\"] == 1:\n",
    "                        counters[face_id][\"L\"] += 1\n",
    "                    \n",
    "                    # 100% accuracy to calculate the count in right eye open and close\n",
    "                    if rEAR < EAR_THRESHOLD and counters[face_id][\"prev_R\"] == 1:\n",
    "                        counters[face_id][\"R\"] += 1\n",
    "\n",
    "                    # Update previous state (1=Open, 0=Closed)\n",
    "                    counters[face_id][\"prev_R\"] = 1 if rEAR > EAR_THRESHOLD else 0\n",
    "                    counters[face_id][\"prev_L\"] = 1 if lEAR > EAR_THRESHOLD else 0\n",
    "                    \n",
    "                    # ------------- MOUTH MAR CALCULATION -------------\n",
    "                    u = face.landmark[Lip_Points[0]] # Upper lip\n",
    "                    l = face.landmark[Lip_Points[1]] # Lower lip\n",
    "                    mar = normalized_lip_distance(u, l)\n",
    "\n",
    "                    # --- MOUTH OPEN DETECTION (Rising Edge Logic) ---\n",
    "                    # 100% accuracy to calculate the count in mouth open (yawn/speech)\n",
    "                    if mar > MAR_THRESHOLD and counters[face_id][\"prev_M\"] == 0:\n",
    "                        counters[face_id][\"M\"] += 1\n",
    "                        counters[face_id][\"prev_M\"] = 1 # Set state to Open\n",
    "                        \n",
    "                    if mar <= MAR_THRESHOLD:\n",
    "                        counters[face_id][\"prev_M\"] = 0 # Set state to Closed\n",
    "\n",
    "                    # ------------- DRAWINGS & TEXT -------------\n",
    "                    x1, y1, x2, y2 = face_box(face, w, h)\n",
    "                    \n",
    "                    # Bounding Box (Yellow)\n",
    "                    cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,255), 2)\n",
    "                    \n",
    "                    # Draw Eyes (Red) and Lips (Blue)\n",
    "                    for p in RE + LE:\n",
    "                        cv2.circle(frame, p, 2, (255,0,0), -1)\n",
    "                        \n",
    "                    # Use pixel coordinates for drawing lips (from pts list for consistency)\n",
    "                    cv2.circle(frame, pts[Lip_Points[0]], 3, (255,100,0), -1) \n",
    "                    cv2.circle(frame, pts[Lip_Points[1]], 3, (255,100,0), -1)\n",
    "                    \n",
    "                    # --- BEAUTIFUL TEXT DISPLAY ---\n",
    "                    # Text positioning variables\n",
    "                    text_x = x1 + 5\n",
    "                    text_y_start = y2 + 20\n",
    "                    line_height = 25\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    font_scale = 0.6\n",
    "                    thickness = 2\n",
    "                    \n",
    "                    # Face ID\n",
    "                    cv2.putText(frame, f\"FACE {face_id} - EAR: {((rEAR+lEAR)/2):.2f}\", (x1, y1-10),\n",
    "                                font, 0.6, (0,255,255), 2)\n",
    "                    \n",
    "                    # Eye Blinks Group (Green)\n",
    "                    cv2.putText(frame, f\"L-Blinks: {counters[face_id]['L']} / R-Blinks: {counters[face_id]['R']}\", \n",
    "                                (text_x, text_y_start), font, font_scale, (0,255,0), thickness)\n",
    "                    \n",
    "                    # Mouth Count Group (Orange)\n",
    "                    cv2.putText(frame, f\"Mouth Opens: {counters[face_id]['M']} (MAR: {mar:.2f})\", \n",
    "                                (text_x, text_y_start + line_height), font, font_scale, (0,128,255), thickness)\n",
    "                    \n",
    "            # --- FPS Feature (Best Feature) ---\n",
    "            c_time = time.time()\n",
    "            fps = 1 / (c_time - p_time) if c_time != p_time else 0.0\n",
    "            p_time = c_time\n",
    "            cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 30), font, 0.7, (255,0,0), 2)\n",
    "\n",
    "            # --- DISPLAY ---\n",
    "            cv2.imshow(\"Face Blink Mouth Detection\", frame)\n",
    "            \n",
    "            # Exit condition\n",
    "            if cv2.waitKey(5) & 0xFF == ord('q'): break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    # RUN\n",
    "if __name__ == \"__main__\":\n",
    "    start_detection()"
   ],
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
